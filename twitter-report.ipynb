{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS as sklearn_stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = text.encode('ascii', 'ignore').decode('utf-8') \n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', ' ', text)  #网址\n",
    "    text = re.sub(r'@\\S+', ' ', text)  # 艾特\n",
    "    text = re.sub(r\"'\", ' ', text)  \n",
    "    text = re.sub(r'%20', ' ', text)\n",
    "    text = re.sub(r'\\w*\\d+\\w*', '', text) # 12abc12\n",
    "    text = re.sub(r' \\d+ ', ' ', text)\n",
    "    table = str.maketrans('','',string.punctuation) # 其他符号\n",
    "    text = text.translate(table)\n",
    "    tmp = text.split()\n",
    "    text = \" \".join(list(filter(lambda x: x not in sklearn_stop_words,tmp)))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>deeds reason earthquake allah forgive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>forest near la ronge sask canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>residents asked shelter place notified officer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>people receive wildfires evacuation orders cal...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>just got sent photo ruby alaska smoke wildfire...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5995</th>\n",
       "      <td>8560</td>\n",
       "      <td>screams</td>\n",
       "      <td>BrasÌ_lia</td>\n",
       "      <td>echoes screams screams</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996</th>\n",
       "      <td>8561</td>\n",
       "      <td>screams</td>\n",
       "      <td>POFFIN</td>\n",
       "      <td>bts song jimin screams screams</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5997</th>\n",
       "      <td>8562</td>\n",
       "      <td>screams</td>\n",
       "      <td>#Gladiator Û¢860Û¢757Û¢</td>\n",
       "      <td>casually phone jasmine cries screams spider sc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5998</th>\n",
       "      <td>8567</td>\n",
       "      <td>screams</td>\n",
       "      <td>W.I.T.S Academy</td>\n",
       "      <td>screams screams</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5999</th>\n",
       "      <td>8570</td>\n",
       "      <td>screams</td>\n",
       "      <td>NaN</td>\n",
       "      <td>update rly life itscreams vibrates handle screams</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  keyword                    location  \\\n",
       "0        1                                  NaN   \n",
       "1        4                                  NaN   \n",
       "2        5                                  NaN   \n",
       "3        6                                  NaN   \n",
       "4        7                                  NaN   \n",
       "...    ...      ...                         ...   \n",
       "5995  8560  screams                   BrasÌ_lia   \n",
       "5996  8561  screams                      POFFIN   \n",
       "5997  8562  screams  #Gladiator Û¢860Û¢757Û¢   \n",
       "5998  8567  screams             W.I.T.S Academy   \n",
       "5999  8570  screams                         NaN   \n",
       "\n",
       "                                                   text  target  \n",
       "0                 deeds reason earthquake allah forgive       1  \n",
       "1                      forest near la ronge sask canada       1  \n",
       "2     residents asked shelter place notified officer...       1  \n",
       "3     people receive wildfires evacuation orders cal...       1  \n",
       "4     just got sent photo ruby alaska smoke wildfire...       1  \n",
       "...                                                 ...     ...  \n",
       "5995                             echoes screams screams       0  \n",
       "5996                     bts song jimin screams screams       0  \n",
       "5997  casually phone jasmine cries screams spider sc...       0  \n",
       "5998                                    screams screams       0  \n",
       "5999  update rly life itscreams vibrates handle screams       0  \n",
       "\n",
       "[6000 rows x 5 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")[:6000]\n",
    "val_df = pd.read_csv(\"train.csv\")[6000:]\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "train_df.keyword = train_df.keyword.fillna(\"\")\n",
    "test_df.keyword = test_df.keyword.fillna(\"\")\n",
    "val_df.keyword = val_df.keyword.fillna(\"\")\n",
    "\n",
    "train_df[\"text\"] = train_df[\"text\"] +\" \"+ train_df[\"keyword\"]\n",
    "test_df[\"text\"] = test_df[\"text\"] +\" \"+ test_df[\"keyword\"]\n",
    "val_df[\"text\"] = val_df[\"text\"] +\" \"+ val_df[\"keyword\"]\n",
    "\n",
    "train_df[\"text\"] = train_df[\"text\"].apply(clean_text)\n",
    "test_df[\"text\"] = test_df[\"text\"].apply(clean_text)\n",
    "val_df[\"text\"] = val_df[\"text\"].apply(clean_text)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "df.keyword = df.keyword.fillna(\"\")\n",
    "df[\"text\"] = df[\"text\"] +\" \"+ df[\"keyword\"]\n",
    "df[\"text\"] = df[\"text\"].apply(clean_text)\n",
    "token_list = [l.split() for l in df.text]\n",
    "num_features = 32\n",
    "min_word_count = 1\n",
    "num_workers = 2\n",
    "window_size = 3  # 上下文窗口大小\n",
    "subsampling = 1e-3 # 高频词条降采样率\n",
    "\n",
    "model = Word2Vec(token_list, workers=num_workers, vector_size=num_features, \n",
    "                 min_count=min_word_count,window=window_size, sample=subsampling)\n",
    "\n",
    "\n",
    "# 保存已训练的模型\n",
    "model_name = \"twitter_32_word2vec_model\"\n",
    "model.save(model_name)\n",
    "\n",
    "# # 测试模型效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import regularizers\n",
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 12000\n",
    "embedding_dim = 32\n",
    "tok = Tokenizer(num_words=max_words)\n",
    "tok.fit_on_texts(train_df.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 's',\n",
       " 2: 't',\n",
       " 3: 'emergency',\n",
       " 4: 'just',\n",
       " 5: 'like',\n",
       " 6: 'amp',\n",
       " 7: 'body',\n",
       " 8: 'disaster',\n",
       " 9: 'burning',\n",
       " 10: 'buildings',\n",
       " 11: 'm',\n",
       " 12: 'new',\n",
       " 13: 'people',\n",
       " 14: 'accident',\n",
       " 15: 'news',\n",
       " 16: 'nuclear',\n",
       " 17: 'police',\n",
       " 18: 'collapse',\n",
       " 19: 'don',\n",
       " 20: 'mass',\n",
       " 21: 'crash',\n",
       " 22: 'fires',\n",
       " 23: 'video',\n",
       " 24: 'attack',\n",
       " 25: 'forest',\n",
       " 26: 'dead',\n",
       " 27: 'death',\n",
       " 28: 'fatal',\n",
       " 29: 'flames',\n",
       " 30: 'fear',\n",
       " 31: 'california',\n",
       " 32: 'damage',\n",
       " 33: 'man',\n",
       " 34: 'day',\n",
       " 35: 'floods',\n",
       " 36: 'bomb',\n",
       " 37: 'got',\n",
       " 38: 'know',\n",
       " 39: 'flood',\n",
       " 40: 'storm',\n",
       " 41: 'injured',\n",
       " 42: 'flooding',\n",
       " 43: 'time',\n",
       " 44: 'going',\n",
       " 45: 'debris',\n",
       " 46: 'fatalities',\n",
       " 47: 'evacuation',\n",
       " 48: 'bags',\n",
       " 49: 'oil',\n",
       " 50: 'army',\n",
       " 51: 'world',\n",
       " 52: 'truck',\n",
       " 53: 'today',\n",
       " 54: 'military',\n",
       " 55: 'evacuate',\n",
       " 56: 'outbreak',\n",
       " 57: 'love',\n",
       " 58: 'derailment',\n",
       " 59: 'spill',\n",
       " 60: 'explosion',\n",
       " 61: 'plan',\n",
       " 62: 'harm',\n",
       " 63: 'collided',\n",
       " 64: 'deluge',\n",
       " 65: 'screaming',\n",
       " 66: 'destroy',\n",
       " 67: 'deaths',\n",
       " 68: 'bloody',\n",
       " 69: 'ambulance',\n",
       " 70: 'fall',\n",
       " 71: 'hurricane',\n",
       " 72: 'natural',\n",
       " 73: 'explode',\n",
       " 74: 'panic',\n",
       " 75: 'heat',\n",
       " 76: 'rt',\n",
       " 77: 'services',\n",
       " 78: 'blood',\n",
       " 79: 'refugees',\n",
       " 80: 'injury',\n",
       " 81: 'murder',\n",
       " 82: 'attacked',\n",
       " 83: 'ruin',\n",
       " 84: 'injuries',\n",
       " 85: 'watch',\n",
       " 86: 'armageddon',\n",
       " 87: 'bridge',\n",
       " 88: 'rescued',\n",
       " 89: 'curfew',\n",
       " 90: 'hostages',\n",
       " 91: 'mudslide',\n",
       " 92: 'sandstorm',\n",
       " 93: 'destruction',\n",
       " 94: 'hail',\n",
       " 95: 'bombed',\n",
       " 96: 'rescuers',\n",
       " 97: 'catastrophe',\n",
       " 98: 'collision',\n",
       " 99: 'loud',\n",
       " 100: 'dust',\n",
       " 101: 'famine',\n",
       " 102: 'massacre',\n",
       " 103: 'quarantined',\n",
       " 104: 'earthquake',\n",
       " 105: 'airplane',\n",
       " 106: 'bag',\n",
       " 107: 'crush',\n",
       " 108: 'danger',\n",
       " 109: 'devastation',\n",
       " 110: 'engulfed',\n",
       " 111: 'burned',\n",
       " 112: 'rioting',\n",
       " 113: 'hazard',\n",
       " 114: 'displaced',\n",
       " 115: 'drought',\n",
       " 116: 'collapsed',\n",
       " 117: 'cliff',\n",
       " 118: 'derailed',\n",
       " 119: 'car',\n",
       " 120: 'destroyed',\n",
       " 121: 'bioterror',\n",
       " 122: 'bleeding',\n",
       " 123: 'riot',\n",
       " 124: 'casualties',\n",
       " 125: 'hazardous',\n",
       " 126: 'landslide',\n",
       " 127: 'derail',\n",
       " 128: 'desolation',\n",
       " 129: 'detonate',\n",
       " 130: 'drowning',\n",
       " 131: 'screamed',\n",
       " 132: 'inundated',\n",
       " 133: 'quarantine',\n",
       " 134: 'want',\n",
       " 135: 'good',\n",
       " 136: 'crashed',\n",
       " 137: 'hiroshima',\n",
       " 138: 'work',\n",
       " 139: 'train',\n",
       " 140: 'drowned',\n",
       " 141: 'electrocuted',\n",
       " 142: 'hellfire',\n",
       " 143: 'hijacker',\n",
       " 144: 'lava',\n",
       " 145: 'pandemonium',\n",
       " 146: 'wave',\n",
       " 147: 'best',\n",
       " 148: 'did',\n",
       " 149: 'families',\n",
       " 150: 'lightning',\n",
       " 151: 'blown',\n",
       " 152: 'collide',\n",
       " 153: 'demolition',\n",
       " 154: 'evacuated',\n",
       " 155: 'exploded',\n",
       " 156: 'fatality',\n",
       " 157: 'flattened',\n",
       " 158: 'bang',\n",
       " 159: 'life',\n",
       " 160: 'years',\n",
       " 161: 'say',\n",
       " 162: 'think',\n",
       " 163: 'let',\n",
       " 164: 'blew',\n",
       " 165: 'drown',\n",
       " 166: 'chemical',\n",
       " 167: 'panicking',\n",
       " 168: 'razed',\n",
       " 169: 'meltdown',\n",
       " 170: 'annihilated',\n",
       " 171: 'u',\n",
       " 172: 'demolish',\n",
       " 173: 'apocalypse',\n",
       " 174: 'hot',\n",
       " 175: 'hostage',\n",
       " 176: 'bagging',\n",
       " 177: 'hijacking',\n",
       " 178: 'ablaze',\n",
       " 179: 'way',\n",
       " 180: 'arson',\n",
       " 181: 'blazing',\n",
       " 182: 'detonation',\n",
       " 183: 'murderer',\n",
       " 184: 'killed',\n",
       " 185: 'war',\n",
       " 186: 'bombing',\n",
       " 187: 'crushed',\n",
       " 188: 'rescue',\n",
       " 189: 'eyewitness',\n",
       " 190: 'reactor',\n",
       " 191: 'obliterated',\n",
       " 192: 'rainstorm',\n",
       " 193: 'legionnaires',\n",
       " 194: 'hijack',\n",
       " 195: 'obliterate',\n",
       " 196: 'need',\n",
       " 197: 'blaze',\n",
       " 198: 'battle',\n",
       " 199: 'casualty',\n",
       " 200: 'responders',\n",
       " 201: 'cyclone',\n",
       " 202: 'electrocute',\n",
       " 203: 'reddit',\n",
       " 204: 'd',\n",
       " 205: 'home',\n",
       " 206: 'catastrophic',\n",
       " 207: 'obliteration',\n",
       " 208: 've',\n",
       " 209: 'really',\n",
       " 210: 'demolished',\n",
       " 211: 'black',\n",
       " 212: 'make',\n",
       " 213: 'right',\n",
       " 214: 'blight',\n",
       " 215: 'read',\n",
       " 216: 'avalanche',\n",
       " 217: 'blizzard',\n",
       " 218: 'school',\n",
       " 219: 'atomic',\n",
       " 220: 'bioterrorism',\n",
       " 221: 'homes',\n",
       " 222: 'year',\n",
       " 223: 'aftershock',\n",
       " 224: 'latest',\n",
       " 225: 'japan',\n",
       " 226: 'deluged',\n",
       " 227: 'hailstorm',\n",
       " 228: 'rubble',\n",
       " 229: 'arsonist',\n",
       " 230: 'content',\n",
       " 231: 'look',\n",
       " 232: 'city',\n",
       " 233: 'help',\n",
       " 234: 'bush',\n",
       " 235: 'desolate',\n",
       " 236: 'annihilation',\n",
       " 237: 'devastated',\n",
       " 238: 'mayhem',\n",
       " 239: 'll',\n",
       " 240: 'lol',\n",
       " 241: 'northern',\n",
       " 242: 'cross',\n",
       " 243: 'water',\n",
       " 244: 'ass',\n",
       " 245: 'near',\n",
       " 246: 'im',\n",
       " 247: 'come',\n",
       " 248: 'hit',\n",
       " 249: 'food',\n",
       " 250: 'shit',\n",
       " 251: 'great',\n",
       " 252: 'getting',\n",
       " 253: 'set',\n",
       " 254: 'night',\n",
       " 255: 'god',\n",
       " 256: 'little',\n",
       " 257: 'wildfire',\n",
       " 258: 'stop',\n",
       " 259: 'times',\n",
       " 260: 'family',\n",
       " 261: 'said',\n",
       " 262: 'coming',\n",
       " 263: 'check',\n",
       " 264: 'face',\n",
       " 265: 'boy',\n",
       " 266: 'migrants',\n",
       " 267: 'live',\n",
       " 268: 'gonna',\n",
       " 269: 'air',\n",
       " 270: 'weather',\n",
       " 271: 'hope',\n",
       " 272: 'fucking',\n",
       " 273: 'cause',\n",
       " 274: 'feel',\n",
       " 275: 'says',\n",
       " 276: 'wind',\n",
       " 277: 'summer',\n",
       " 278: 'free',\n",
       " 279: 'save',\n",
       " 280: 'bad',\n",
       " 281: 'charged',\n",
       " 282: 'lives',\n",
       " 283: 'w',\n",
       " 284: 'high',\n",
       " 285: 'liked',\n",
       " 286: 'hundreds',\n",
       " 287: 'end',\n",
       " 288: 'looks',\n",
       " 289: 'house',\n",
       " 290: 'iran',\n",
       " 291: 'women',\n",
       " 292: 'real',\n",
       " 293: 'missing',\n",
       " 294: 'dont',\n",
       " 295: 'screams',\n",
       " 296: 'tonight',\n",
       " 297: 'road',\n",
       " 298: 'state',\n",
       " 299: 'fedex',\n",
       " 300: 'anniversary',\n",
       " 301: 'rain',\n",
       " 302: 'game',\n",
       " 303: 'run',\n",
       " 304: 'big',\n",
       " 305: 'post',\n",
       " 306: 'market',\n",
       " 307: 'boat',\n",
       " 308: 'breaking',\n",
       " 309: 'head',\n",
       " 310: 'past',\n",
       " 311: 'away',\n",
       " 312: 'white',\n",
       " 313: 'twitter',\n",
       " 314: 'obama',\n",
       " 315: 'woman',\n",
       " 316: 'longer',\n",
       " 317: 'report',\n",
       " 318: 'affected',\n",
       " 319: 'bus',\n",
       " 320: 'does',\n",
       " 321: 'came',\n",
       " 322: 'reunion',\n",
       " 323: 'national',\n",
       " 324: 'girl',\n",
       " 325: 'things',\n",
       " 326: 'story',\n",
       " 327: 'shoulder',\n",
       " 328: 'send',\n",
       " 329: 'china',\n",
       " 330: 'blast',\n",
       " 331: 'prebreak',\n",
       " 332: 'photo',\n",
       " 333: 'update',\n",
       " 334: 'week',\n",
       " 335: 'traffic',\n",
       " 336: 'left',\n",
       " 337: 'doing',\n",
       " 338: 'went',\n",
       " 339: 'fan',\n",
       " 340: 'service',\n",
       " 341: 'area',\n",
       " 342: 'st',\n",
       " 343: 'better',\n",
       " 344: 'pm',\n",
       " 345: 'horrible',\n",
       " 346: 'heard',\n",
       " 347: 'island',\n",
       " 348: 'river',\n",
       " 349: 'kill',\n",
       " 350: 'tomorrow',\n",
       " 351: 'fuck',\n",
       " 352: 'power',\n",
       " 353: 'land',\n",
       " 354: 'baby',\n",
       " 355: 'sue',\n",
       " 356: 'died',\n",
       " 357: 'cool',\n",
       " 358: 'care',\n",
       " 359: 'minute',\n",
       " 360: 'possible',\n",
       " 361: 'goes',\n",
       " 362: 'government',\n",
       " 363: 'airport',\n",
       " 364: 'phone',\n",
       " 365: 'long',\n",
       " 366: 'calgary',\n",
       " 367: 'lab',\n",
       " 368: 'song',\n",
       " 369: 'light',\n",
       " 370: 'policy',\n",
       " 371: 'stock',\n",
       " 372: 'use',\n",
       " 373: 'thank',\n",
       " 374: 'thing',\n",
       " 375: 'brown',\n",
       " 376: 'wake',\n",
       " 377: 'ebay',\n",
       " 378: 'thought',\n",
       " 379: 'red',\n",
       " 380: 'sound',\n",
       " 381: 'group',\n",
       " 382: 'health',\n",
       " 383: 'change',\n",
       " 384: 'oh',\n",
       " 385: 'ur',\n",
       " 386: 'nearby',\n",
       " 387: 'offensive',\n",
       " 388: 'building',\n",
       " 389: 'far',\n",
       " 390: 'used',\n",
       " 391: 'n',\n",
       " 392: 'shooting',\n",
       " 393: 'play',\n",
       " 394: 'men',\n",
       " 395: 'heart',\n",
       " 396: 'officials',\n",
       " 397: 'old',\n",
       " 398: 'plans',\n",
       " 399: 'issues',\n",
       " 400: 'believe',\n",
       " 401: 'peace',\n",
       " 402: 'children',\n",
       " 403: 'india',\n",
       " 404: 'music',\n",
       " 405: 'half',\n",
       " 406: 'bigger',\n",
       " 407: 'rise',\n",
       " 408: 'yearold',\n",
       " 409: 'swallowed',\n",
       " 410: 'south',\n",
       " 411: 'thanks',\n",
       " 412: 'tell',\n",
       " 413: 'support',\n",
       " 414: 'aircraft',\n",
       " 415: 'won',\n",
       " 416: 'bar',\n",
       " 417: 'soon',\n",
       " 418: 'start',\n",
       " 419: 'data',\n",
       " 420: 'pick',\n",
       " 421: 'amid',\n",
       " 422: 'stay',\n",
       " 423: 'media',\n",
       " 424: 'remember',\n",
       " 425: 'deal',\n",
       " 426: 'sure',\n",
       " 427: 'transport',\n",
       " 428: 'wanna',\n",
       " 429: 'searching',\n",
       " 430: 'effect',\n",
       " 431: 'manslaughter',\n",
       " 432: 'projected',\n",
       " 433: 'county',\n",
       " 434: 'kids',\n",
       " 435: 'actually',\n",
       " 436: 'die',\n",
       " 437: 'job',\n",
       " 438: 'plane',\n",
       " 439: 'bc',\n",
       " 440: 'warning',\n",
       " 441: 'crisis',\n",
       " 442: 'yeah',\n",
       " 443: 'having',\n",
       " 444: 'yes',\n",
       " 445: 'probably',\n",
       " 446: 'bodies',\n",
       " 447: 'place',\n",
       " 448: 'days',\n",
       " 449: 'flag',\n",
       " 450: 'leave',\n",
       " 451: 'north',\n",
       " 452: 'making',\n",
       " 453: 'ago',\n",
       " 454: 'feared',\n",
       " 455: 'helicopter',\n",
       " 456: 'lot',\n",
       " 457: 'fun',\n",
       " 458: 'order',\n",
       " 459: 'august',\n",
       " 460: 'movie',\n",
       " 461: 'leather',\n",
       " 462: 'american',\n",
       " 463: 'makes',\n",
       " 464: 'business',\n",
       " 465: 'trying',\n",
       " 466: 'youth',\n",
       " 467: 'person',\n",
       " 468: 'doesn',\n",
       " 469: 'line',\n",
       " 470: 'photos',\n",
       " 471: 'saved',\n",
       " 472: 'waves',\n",
       " 473: 'epicentre',\n",
       " 474: 'hat',\n",
       " 475: 'refugio',\n",
       " 476: 'costlier',\n",
       " 477: 'la',\n",
       " 478: 'wait',\n",
       " 479: 'second',\n",
       " 480: 'inside',\n",
       " 481: 'shot',\n",
       " 482: 'america',\n",
       " 483: 'rd',\n",
       " 484: 'gets',\n",
       " 485: 'jobs',\n",
       " 486: 'history',\n",
       " 487: 'ball',\n",
       " 488: 'hell',\n",
       " 489: 'stand',\n",
       " 490: 'hours',\n",
       " 491: 'b',\n",
       " 492: 'israeli',\n",
       " 493: 'literally',\n",
       " 494: 'beautiful',\n",
       " 495: 'anthrax',\n",
       " 496: 'computers',\n",
       " 497: 'russian',\n",
       " 498: 'angry',\n",
       " 499: 'trains',\n",
       " 500: 'malaysia',\n",
       " 501: 'abc',\n",
       " 502: 'banned',\n",
       " 503: 'ignition',\n",
       " 504: 'knock',\n",
       " 505: 'picking',\n",
       " 506: 'radiation',\n",
       " 507: 'myanmar',\n",
       " 508: 'finally',\n",
       " 509: 'ok',\n",
       " 510: 'case',\n",
       " 511: 'maybe',\n",
       " 512: 'hey',\n",
       " 513: 'child',\n",
       " 514: 'totally',\n",
       " 515: 'toddler',\n",
       " 516: 'saw',\n",
       " 517: 'town',\n",
       " 518: 'team',\n",
       " 519: 'guys',\n",
       " 520: 'fukushima',\n",
       " 521: 'mishaps',\n",
       " 522: 'money',\n",
       " 523: 'ladies',\n",
       " 524: 'appears',\n",
       " 525: 'centre',\n",
       " 526: 'village',\n",
       " 527: 'houses',\n",
       " 528: 'caused',\n",
       " 529: 'course',\n",
       " 530: 'severe',\n",
       " 531: 'inundation',\n",
       " 532: 'disea',\n",
       " 533: 'closed',\n",
       " 534: 'heavy',\n",
       " 535: 'try',\n",
       " 536: 'center',\n",
       " 537: 'vehicle',\n",
       " 538: 'didn',\n",
       " 539: 'guy',\n",
       " 540: 'eyes',\n",
       " 541: 'omg',\n",
       " 542: 'couple',\n",
       " 543: 'sorry',\n",
       " 544: 'vs',\n",
       " 545: 'self',\n",
       " 546: 'fight',\n",
       " 547: 'class',\n",
       " 548: 'friend',\n",
       " 549: 'tv',\n",
       " 550: 'control',\n",
       " 551: 'temple',\n",
       " 552: 'germs',\n",
       " 553: 'words',\n",
       " 554: 'pay',\n",
       " 555: 'womens',\n",
       " 556: 'meek',\n",
       " 557: 'giant',\n",
       " 558: 'marks',\n",
       " 559: 'memories',\n",
       " 560: 'crews',\n",
       " 561: 'flash',\n",
       " 562: 'lord',\n",
       " 563: 'outside',\n",
       " 564: 'r',\n",
       " 565: 'hard',\n",
       " 566: 'nowplaying',\n",
       " 567: 'win',\n",
       " 568: 'daily',\n",
       " 569: 'experts',\n",
       " 570: 'official',\n",
       " 571: 'hate',\n",
       " 572: 'usa',\n",
       " 573: 'united',\n",
       " 574: 'gt',\n",
       " 575: 'mop',\n",
       " 576: 'beach',\n",
       " 577: 'reports',\n",
       " 578: 'hiring',\n",
       " 579: 'theater',\n",
       " 580: 'gun',\n",
       " 581: 'christian',\n",
       " 582: 'muslims',\n",
       " 583: 'listen',\n",
       " 584: 'star',\n",
       " 585: 'eye',\n",
       " 586: 'space',\n",
       " 587: 'taken',\n",
       " 588: 'australia',\n",
       " 589: 'action',\n",
       " 590: 'nearly',\n",
       " 591: 'c',\n",
       " 592: 'cake',\n",
       " 593: 'level',\n",
       " 594: 'link',\n",
       " 595: 'watching',\n",
       " 596: 'drake',\n",
       " 597: 'outrage',\n",
       " 598: 'gbbo',\n",
       " 599: 'madhya',\n",
       " 600: 'pradesh',\n",
       " 601: 'led',\n",
       " 602: 'gems',\n",
       " 603: 'funtenna',\n",
       " 604: 'subreddits',\n",
       " 605: 'reason',\n",
       " 606: 'lost',\n",
       " 607: 'fast',\n",
       " 608: 'cars',\n",
       " 609: 'climate',\n",
       " 610: 'huge',\n",
       " 611: 'reported',\n",
       " 612: 'mom',\n",
       " 613: 'property',\n",
       " 614: 'moment',\n",
       " 615: 'book',\n",
       " 616: 'dog',\n",
       " 617: 'seen',\n",
       " 618: 'park',\n",
       " 619: 'disease',\n",
       " 620: 'hand',\n",
       " 621: 'lets',\n",
       " 622: 'till',\n",
       " 623: 'date',\n",
       " 624: 'caught',\n",
       " 625: 'green',\n",
       " 626: 'militants',\n",
       " 627: 'bombs',\n",
       " 628: 'mount',\n",
       " 629: 'pamela',\n",
       " 630: 'needs',\n",
       " 631: 'playing',\n",
       " 632: 'running',\n",
       " 633: 'mad',\n",
       " 634: 'tweet',\n",
       " 635: 'morning',\n",
       " 636: 'wow',\n",
       " 637: 'fashion',\n",
       " 638: 'pray',\n",
       " 639: 'alarm',\n",
       " 640: 'camp',\n",
       " 641: 'hear',\n",
       " 642: 'chance',\n",
       " 643: 'friends',\n",
       " 644: 'patience',\n",
       " 645: 'lamp',\n",
       " 646: 'bayelsa',\n",
       " 647: 'parole',\n",
       " 648: 'unconfirmed',\n",
       " 649: 'neighbour',\n",
       " 650: 'colorado',\n",
       " 651: 'street',\n",
       " 652: 'bring',\n",
       " 653: 'awesome',\n",
       " 654: 'wanted',\n",
       " 655: 'west',\n",
       " 656: 'thousands',\n",
       " 657: 'happy',\n",
       " 658: 'happened',\n",
       " 659: 'france',\n",
       " 660: 'wednesday',\n",
       " 661: 'pakistani',\n",
       " 662: 'trust',\n",
       " 663: 'israel',\n",
       " 664: 'sign',\n",
       " 665: 'major',\n",
       " 666: 'following',\n",
       " 667: 'poor',\n",
       " 668: 'film',\n",
       " 669: 'comes',\n",
       " 670: 'escape',\n",
       " 671: 'russia',\n",
       " 672: 'blue',\n",
       " 673: 'east',\n",
       " 674: 'arrested',\n",
       " 675: 'true',\n",
       " 676: 'damn',\n",
       " 677: 'waving',\n",
       " 678: 'geller',\n",
       " 679: 'worst',\n",
       " 680: 'driving',\n",
       " 681: 'ebola',\n",
       " 682: 'dude',\n",
       " 683: 'pain',\n",
       " 684: 'info',\n",
       " 685: 'rock',\n",
       " 686: 'low',\n",
       " 687: 'tote',\n",
       " 688: 'handbag',\n",
       " 689: 'libya',\n",
       " 690: 'holding',\n",
       " 691: 'mph',\n",
       " 692: 'ppl',\n",
       " 693: 'confirmed',\n",
       " 694: 'cree',\n",
       " 695: 'sick',\n",
       " 696: 'islam',\n",
       " 697: 'crematoria',\n",
       " 698: 'nigerian',\n",
       " 699: 'haha',\n",
       " 700: 'aba',\n",
       " 701: 'site',\n",
       " 702: 'ave',\n",
       " 703: 'talk',\n",
       " 704: 'drive',\n",
       " 705: 'seeing',\n",
       " 706: 'wrong',\n",
       " 707: 'suspect',\n",
       " 708: 'crazy',\n",
       " 709: 'kills',\n",
       " 710: 'driver',\n",
       " 711: 'safety',\n",
       " 712: 'country',\n",
       " 713: 'isn',\n",
       " 714: 'japanese',\n",
       " 715: 'learn',\n",
       " 716: 'ca',\n",
       " 717: 'public',\n",
       " 718: 'pretty',\n",
       " 719: 'ahead',\n",
       " 720: 'party',\n",
       " 721: 'online',\n",
       " 722: 'turn',\n",
       " 723: 'ain',\n",
       " 724: 'point',\n",
       " 725: 'spot',\n",
       " 726: 'investigating',\n",
       " 727: 'aug',\n",
       " 728: 'businesses',\n",
       " 729: 'downtown',\n",
       " 730: 'parents',\n",
       " 731: 'delivers',\n",
       " 732: 'isis',\n",
       " 733: 'govt',\n",
       " 734: 'york',\n",
       " 735: 'passengers',\n",
       " 736: 'apollo',\n",
       " 737: 'provoke',\n",
       " 738: 'offroad',\n",
       " 739: 'jonathan',\n",
       " 740: 'governor',\n",
       " 741: 'secret',\n",
       " 742: 'double',\n",
       " 743: 'scene',\n",
       " 744: 'global',\n",
       " 745: 'gtgt',\n",
       " 746: 'ready',\n",
       " 747: 'wild',\n",
       " 748: 'horse',\n",
       " 749: 'human',\n",
       " 750: 'radio',\n",
       " 751: 'mod',\n",
       " 752: 'scared',\n",
       " 753: 'department',\n",
       " 754: 'earth',\n",
       " 755: 'working',\n",
       " 756: 'lmao',\n",
       " 757: 'okay',\n",
       " 758: 'feeling',\n",
       " 759: 'f',\n",
       " 760: 'looking',\n",
       " 761: 'niggas',\n",
       " 762: 'e',\n",
       " 763: 'follow',\n",
       " 764: 'told',\n",
       " 765: 'faux',\n",
       " 766: 'middle',\n",
       " 767: 'thursday',\n",
       " 768: 'likely',\n",
       " 769: 'x',\n",
       " 770: 'sad',\n",
       " 771: 'instead',\n",
       " 772: 'fans',\n",
       " 773: 'sea',\n",
       " 774: 'quiz',\n",
       " 775: 'enugu',\n",
       " 776: 'spring',\n",
       " 777: 'wonder',\n",
       " 778: 'wrought',\n",
       " 779: 'internally',\n",
       " 780: 'travel',\n",
       " 781: 'smoke',\n",
       " 782: 'happening',\n",
       " 783: 'london',\n",
       " 784: 'taking',\n",
       " 785: 'involving',\n",
       " 786: 'dies',\n",
       " 787: 'turned',\n",
       " 788: 'financial',\n",
       " 789: 'thinking',\n",
       " 790: 'tried',\n",
       " 791: 'mode',\n",
       " 792: 'pakistan',\n",
       " 793: 'total',\n",
       " 794: 'took',\n",
       " 795: 'bed',\n",
       " 796: 'series',\n",
       " 797: 'prepare',\n",
       " 798: 'vote',\n",
       " 799: 'dogs',\n",
       " 800: 'hero',\n",
       " 801: 'linked',\n",
       " 802: 'million',\n",
       " 803: 'gave',\n",
       " 804: 'internet',\n",
       " 805: 'response',\n",
       " 806: 'lt',\n",
       " 807: 'louis',\n",
       " 808: 'album',\n",
       " 809: 'added',\n",
       " 810: 'occurred',\n",
       " 811: 'young',\n",
       " 812: 'miss',\n",
       " 813: 'research',\n",
       " 814: 'cut',\n",
       " 815: 'problem',\n",
       " 816: 'living',\n",
       " 817: 'silver',\n",
       " 818: 'cold',\n",
       " 819: 'giving',\n",
       " 820: 'walking',\n",
       " 821: 'feet',\n",
       " 822: 'entire',\n",
       " 823: 'soul',\n",
       " 824: 'metro',\n",
       " 825: 'aren',\n",
       " 826: 'biggest',\n",
       " 827: 'broke',\n",
       " 828: 'standard',\n",
       " 829: 'friday',\n",
       " 830: 'killer',\n",
       " 831: 'strike',\n",
       " 832: 'purse',\n",
       " 833: 'saying',\n",
       " 834: 'small',\n",
       " 835: 'washington',\n",
       " 836: 'gunman',\n",
       " 837: 'coast',\n",
       " 838: 'ground',\n",
       " 839: 'nagasaki',\n",
       " 840: 'worse',\n",
       " 841: 'western',\n",
       " 842: 'different',\n",
       " 843: 'press',\n",
       " 844: 'planned',\n",
       " 845: 'sounds',\n",
       " 846: 'account',\n",
       " 847: 'takes',\n",
       " 848: 'british',\n",
       " 849: 'absolutely',\n",
       " 850: 'guide',\n",
       " 851: 'uk',\n",
       " 852: 'flight',\n",
       " 853: 'international',\n",
       " 854: 'smaug',\n",
       " 855: 'sensorsenso',\n",
       " 856: 'struggles',\n",
       " 857: 'apc',\n",
       " 858: 'specially',\n",
       " 859: 'allows',\n",
       " 860: 'alabama',\n",
       " 861: 'cameroon',\n",
       " 862: 'orders',\n",
       " 863: 'causes',\n",
       " 864: 'metal',\n",
       " 865: 'sky',\n",
       " 866: 'season',\n",
       " 867: 'wife',\n",
       " 868: 'setting',\n",
       " 869: 'later',\n",
       " 870: 'means',\n",
       " 871: 'month',\n",
       " 872: 'blocked',\n",
       " 873: 'happen',\n",
       " 874: 'using',\n",
       " 875: 'guess',\n",
       " 876: 'wants',\n",
       " 877: 'youtube',\n",
       " 878: 'begin',\n",
       " 879: 'members',\n",
       " 880: 'victim',\n",
       " 881: 'ship',\n",
       " 882: 'petition',\n",
       " 883: 'feat',\n",
       " 884: 'paul',\n",
       " 885: 'survivors',\n",
       " 886: 'syrian',\n",
       " 887: 'pile',\n",
       " 888: 'wasn',\n",
       " 889: 'salt',\n",
       " 890: 'kinda',\n",
       " 891: 'played',\n",
       " 892: 'dad',\n",
       " 893: 'queen',\n",
       " 894: 'sense',\n",
       " 895: 'door',\n",
       " 896: 'haven',\n",
       " 897: 'direction',\n",
       " 898: 'indian',\n",
       " 899: 'udhampur',\n",
       " 900: 'gop',\n",
       " 901: 'worth',\n",
       " 902: 'fully',\n",
       " 903: 'favorite',\n",
       " 904: 'playlist',\n",
       " 905: 'ships',\n",
       " 906: 'dc',\n",
       " 907: 'future',\n",
       " 908: 'firefighters',\n",
       " 909: 'lady',\n",
       " 910: 'p',\n",
       " 911: 'text',\n",
       " 912: 'glass',\n",
       " 913: 'wedding',\n",
       " 914: 'falling',\n",
       " 915: 'open',\n",
       " 916: 'walk',\n",
       " 917: 'wall',\n",
       " 918: 'mean',\n",
       " 919: 'large',\n",
       " 920: 'effects',\n",
       " 921: 'carrying',\n",
       " 922: 'ashes',\n",
       " 923: 'trent',\n",
       " 924: 'central',\n",
       " 925: 'cranes',\n",
       " 926: 'ross',\n",
       " 927: 'sex',\n",
       " 928: 'express',\n",
       " 929: 'population',\n",
       " 930: 'denver',\n",
       " 931: 'felt',\n",
       " 932: 'animal',\n",
       " 933: 'gold',\n",
       " 934: 'room',\n",
       " 935: 'phoenix',\n",
       " 936: 'airlines',\n",
       " 937: 'interesting',\n",
       " 938: 'evening',\n",
       " 939: 'search',\n",
       " 940: 'med',\n",
       " 941: 'kit',\n",
       " 942: 'declares',\n",
       " 943: 'philippines',\n",
       " 944: 'roosevelt',\n",
       " 945: 'modified',\n",
       " 946: 'stadium',\n",
       " 947: 'repatriated',\n",
       " 948: 'wildfires',\n",
       " 949: 'sent',\n",
       " 950: 'lake',\n",
       " 951: 'nyc',\n",
       " 952: 'office',\n",
       " 953: 'cruz',\n",
       " 954: 'students',\n",
       " 955: 'edm',\n",
       " 956: 'michael',\n",
       " 957: 'risk',\n",
       " 958: 'owner',\n",
       " 959: 'dr',\n",
       " 960: 'issue',\n",
       " 961: 'dance',\n",
       " 962: 'avoid',\n",
       " 963: 'examining',\n",
       " 964: 'bin',\n",
       " 965: 'gov',\n",
       " 966: 'wtf',\n",
       " 967: 'close',\n",
       " 968: 'hospital',\n",
       " 969: 'reuters',\n",
       " 970: 'lucky',\n",
       " 971: 'number',\n",
       " 972: 'drunk',\n",
       " 973: 'horror',\n",
       " 974: 'match',\n",
       " 975: 'false',\n",
       " 976: 'jeb',\n",
       " 977: 'survive',\n",
       " 978: 'feels',\n",
       " 979: 'beat',\n",
       " 980: 'girls',\n",
       " 981: 'loved',\n",
       " 982: 'lead',\n",
       " 983: 'navy',\n",
       " 984: 'crime',\n",
       " 985: 'burn',\n",
       " 986: 'victims',\n",
       " 987: 'palestinian',\n",
       " 988: 'bay',\n",
       " 989: 'suspected',\n",
       " 990: 'nice',\n",
       " 991: 'worry',\n",
       " 992: 'act',\n",
       " 993: 'fat',\n",
       " 994: 'view',\n",
       " 995: 'answer',\n",
       " 996: 'yo',\n",
       " 997: 'general',\n",
       " 998: 'king',\n",
       " 999: 'pathogens',\n",
       " 1000: 'potential',\n",
       " ...}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"twitter_32_word2vec_model\"\n",
    "Word2Vec_model = Word2Vec.load(model_name)\n",
    "weight = np.zeros((max_words,embedding_dim))\n",
    "for i in range(1,max_words):\n",
    "    weight[i] = Word2Vec_model.wv[tok.index_word.get(i,'?')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seq = tok.texts_to_sequences(train_df.text)\n",
    "val_seq = tok.texts_to_sequences(val_df.text)\n",
    "test_seq = tok.texts_to_sequences(test_df.text)\n",
    "\n",
    "train_matrix = tok.texts_to_matrix(train_df.text)\n",
    "val_matrix = tok.texts_to_matrix(val_df.text)\n",
    "test_matrix = tok.texts_to_matrix(test_df.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seq_mat = sequence.pad_sequences(train_seq,maxlen=max_len)\n",
    "test_seq_mat = sequence.pad_sequences(test_seq,maxlen=max_len)\n",
    "val_seq_mat = sequence.pad_sequences(val_seq,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 32)                384032    \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 8)                 264       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 384,305\n",
      "Trainable params: 384,305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(32, activation='relu',input_shape=(max_words,)))\n",
    "model.add(layers.Dense(8, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "             loss = 'binary_crossentropy',\n",
    "             metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6000 samples, validate on 1613 samples\n",
      "Epoch 1/20\n",
      "6000/6000 [==============================] - 1s 165us/step - loss: 0.6486 - accuracy: 0.7000 - val_loss: 0.6158 - val_accuracy: 0.7526\n",
      "Epoch 2/20\n",
      "6000/6000 [==============================] - 1s 110us/step - loss: 0.5054 - accuracy: 0.8412 - val_loss: 0.5348 - val_accuracy: 0.7855\n",
      "Epoch 3/20\n",
      "6000/6000 [==============================] - 1s 108us/step - loss: 0.3803 - accuracy: 0.8720 - val_loss: 0.4890 - val_accuracy: 0.7880\n",
      "Epoch 4/20\n",
      "6000/6000 [==============================] - 1s 111us/step - loss: 0.2989 - accuracy: 0.8948 - val_loss: 0.4816 - val_accuracy: 0.7799\n",
      "Epoch 5/20\n",
      "6000/6000 [==============================] - 1s 108us/step - loss: 0.2470 - accuracy: 0.9122 - val_loss: 0.4959 - val_accuracy: 0.7657\n",
      "Epoch 6/20\n",
      "6000/6000 [==============================] - 1s 107us/step - loss: 0.2084 - accuracy: 0.9275 - val_loss: 0.5287 - val_accuracy: 0.7570\n",
      "Epoch 7/20\n",
      "6000/6000 [==============================] - 1s 110us/step - loss: 0.1788 - accuracy: 0.9387 - val_loss: 0.5634 - val_accuracy: 0.7495\n",
      "Epoch 8/20\n",
      "6000/6000 [==============================] - 1s 108us/step - loss: 0.1554 - accuracy: 0.9447 - val_loss: 0.6211 - val_accuracy: 0.7402\n",
      "Epoch 9/20\n",
      "6000/6000 [==============================] - 1s 107us/step - loss: 0.1371 - accuracy: 0.9523 - val_loss: 0.6455 - val_accuracy: 0.7421\n",
      "Epoch 10/20\n",
      "6000/6000 [==============================] - 1s 107us/step - loss: 0.1223 - accuracy: 0.9572 - val_loss: 0.7193 - val_accuracy: 0.7297\n",
      "Epoch 11/20\n",
      "6000/6000 [==============================] - 1s 108us/step - loss: 0.1084 - accuracy: 0.9612 - val_loss: 0.7450 - val_accuracy: 0.7359\n",
      "Epoch 12/20\n",
      "6000/6000 [==============================] - 1s 109us/step - loss: 0.0989 - accuracy: 0.9643 - val_loss: 0.8219 - val_accuracy: 0.7216\n",
      "Epoch 13/20\n",
      "6000/6000 [==============================] - 1s 110us/step - loss: 0.0901 - accuracy: 0.9692 - val_loss: 0.8779 - val_accuracy: 0.7179\n",
      "Epoch 14/20\n",
      "6000/6000 [==============================] - 1s 107us/step - loss: 0.0835 - accuracy: 0.9700 - val_loss: 0.9270 - val_accuracy: 0.7204\n",
      "Epoch 15/20\n",
      "6000/6000 [==============================] - 1s 109us/step - loss: 0.0771 - accuracy: 0.9728 - val_loss: 1.0164 - val_accuracy: 0.7030\n",
      "Epoch 16/20\n",
      "6000/6000 [==============================] - 1s 109us/step - loss: 0.0730 - accuracy: 0.9738 - val_loss: 1.0272 - val_accuracy: 0.7154\n",
      "Epoch 17/20\n",
      "6000/6000 [==============================] - 1s 107us/step - loss: 0.0683 - accuracy: 0.9752 - val_loss: 1.0835 - val_accuracy: 0.7105\n",
      "Epoch 18/20\n",
      "6000/6000 [==============================] - 1s 110us/step - loss: 0.0652 - accuracy: 0.9765 - val_loss: 1.1319 - val_accuracy: 0.7111\n",
      "Epoch 19/20\n",
      "6000/6000 [==============================] - ETA: 0s - loss: 0.0612 - accuracy: 0.97 - 1s 109us/step - loss: 0.0616 - accuracy: 0.9765 - val_loss: 1.2200 - val_accuracy: 0.6981\n",
      "Epoch 20/20\n",
      "6000/6000 [==============================] - 1s 108us/step - loss: 0.0603 - accuracy: 0.9767 - val_loss: 1.2648 - val_accuracy: 0.6956\n"
     ]
    }
   ],
   "source": [
    "history_dense = model.fit(train_matrix,\n",
    "                    train_df.target,\n",
    "                   epochs=20,\n",
    "                   batch_size = 128,\n",
    "                   validation_data =(val_matrix,val_df.target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 25, 32)            384000    \n",
      "_________________________________________________________________\n",
      "simple_rnn_3 (SimpleRNN)     (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 386,113\n",
      "Trainable params: 386,113\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Embedding(input_dim=max_words, output_dim=embedding_dim,\n",
    "                           input_length = max_len))\n",
    "\n",
    "model.add(layers.SimpleRNN(32))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "             loss = 'binary_crossentropy',\n",
    "             metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\school\\aconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6000 samples, validate on 1613 samples\n",
      "Epoch 1/20\n",
      "6000/6000 [==============================] - 1s 144us/step - loss: 0.6448 - accuracy: 0.6340 - val_loss: 0.6584 - val_accuracy: 0.6144\n",
      "Epoch 2/20\n",
      "6000/6000 [==============================] - 1s 105us/step - loss: 0.4678 - accuracy: 0.8215 - val_loss: 0.6547 - val_accuracy: 0.5828\n",
      "Epoch 3/20\n",
      "6000/6000 [==============================] - 1s 104us/step - loss: 0.2827 - accuracy: 0.9045 - val_loss: 0.6603 - val_accuracy: 0.6683\n",
      "Epoch 4/20\n",
      "6000/6000 [==============================] - 1s 106us/step - loss: 0.1783 - accuracy: 0.9432 - val_loss: 0.6437 - val_accuracy: 0.6844\n",
      "Epoch 5/20\n",
      "6000/6000 [==============================] - 1s 104us/step - loss: 0.1248 - accuracy: 0.9600 - val_loss: 0.6869 - val_accuracy: 0.6702\n",
      "Epoch 6/20\n",
      "6000/6000 [==============================] - 1s 107us/step - loss: 0.0996 - accuracy: 0.9657 - val_loss: 0.7402 - val_accuracy: 0.6355\n",
      "Epoch 7/20\n",
      "6000/6000 [==============================] - 1s 108us/step - loss: 0.0847 - accuracy: 0.9700 - val_loss: 0.7649 - val_accuracy: 0.6584\n",
      "Epoch 8/20\n",
      "6000/6000 [==============================] - 1s 106us/step - loss: 0.0759 - accuracy: 0.9715 - val_loss: 0.8044 - val_accuracy: 0.6193\n",
      "Epoch 9/20\n",
      "6000/6000 [==============================] - 1s 107us/step - loss: 0.0694 - accuracy: 0.9752 - val_loss: 0.7849 - val_accuracy: 0.6435\n",
      "Epoch 10/20\n",
      "6000/6000 [==============================] - 1s 105us/step - loss: 0.0665 - accuracy: 0.9750 - val_loss: 0.8087 - val_accuracy: 0.6392\n",
      "Epoch 11/20\n",
      "6000/6000 [==============================] - 1s 106us/step - loss: 0.0638 - accuracy: 0.9760 - val_loss: 0.8139 - val_accuracy: 0.6404\n",
      "Epoch 12/20\n",
      "6000/6000 [==============================] - 1s 106us/step - loss: 0.0589 - accuracy: 0.9750 - val_loss: 0.8322 - val_accuracy: 0.6317\n",
      "Epoch 13/20\n",
      "6000/6000 [==============================] - 1s 107us/step - loss: 0.0578 - accuracy: 0.9777 - val_loss: 0.8802 - val_accuracy: 0.6156\n",
      "Epoch 14/20\n",
      "6000/6000 [==============================] - 1s 105us/step - loss: 0.0555 - accuracy: 0.9783 - val_loss: 0.8549 - val_accuracy: 0.6386\n",
      "Epoch 15/20\n",
      "6000/6000 [==============================] - 1s 107us/step - loss: 0.0550 - accuracy: 0.9785 - val_loss: 0.8829 - val_accuracy: 0.6187\n",
      "Epoch 16/20\n",
      "6000/6000 [==============================] - 1s 107us/step - loss: 0.0521 - accuracy: 0.9787 - val_loss: 0.8648 - val_accuracy: 0.6262\n",
      "Epoch 17/20\n",
      "6000/6000 [==============================] - 1s 106us/step - loss: 0.0517 - accuracy: 0.9775 - val_loss: 0.8713 - val_accuracy: 0.6293\n",
      "Epoch 18/20\n",
      "6000/6000 [==============================] - 1s 107us/step - loss: 0.0504 - accuracy: 0.9772 - val_loss: 0.8633 - val_accuracy: 0.6212\n",
      "Epoch 19/20\n",
      "6000/6000 [==============================] - 1s 105us/step - loss: 0.0489 - accuracy: 0.9782 - val_loss: 0.8763 - val_accuracy: 0.6181\n",
      "Epoch 20/20\n",
      "6000/6000 [==============================] - 1s 108us/step - loss: 0.0491 - accuracy: 0.9783 - val_loss: 0.8786 - val_accuracy: 0.6280\n"
     ]
    }
   ],
   "source": [
    "history_rnn = model.fit(train_seq_mat,\n",
    "                    train_df.target,\n",
    "                   epochs=20,\n",
    "                   batch_size = 128,\n",
    "                   validation_data =(val_seq_mat,val_df.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, 25, 32)            384000    \n",
      "_________________________________________________________________\n",
      "simple_rnn_4 (SimpleRNN)     (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 386,113\n",
      "Trainable params: 2,113\n",
      "Non-trainable params: 384,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Embedding(input_dim=max_words, output_dim=embedding_dim,\n",
    "                           input_length = max_len,\n",
    "                           weights=[weight],\n",
    "                           trainable=False))\n",
    "\n",
    "model.add(layers.SimpleRNN(32))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "             loss = 'binary_crossentropy',\n",
    "             metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6000 samples, validate on 1613 samples\n",
      "Epoch 1/20\n",
      "6000/6000 [==============================] - 1s 130us/step - loss: 0.6685 - accuracy: 0.5960 - val_loss: 0.6579 - val_accuracy: 0.6181\n",
      "Epoch 2/20\n",
      "6000/6000 [==============================] - 1s 95us/step - loss: 0.6529 - accuracy: 0.6190 - val_loss: 0.6463 - val_accuracy: 0.6293\n",
      "Epoch 3/20\n",
      "6000/6000 [==============================] - 1s 95us/step - loss: 0.6455 - accuracy: 0.6320 - val_loss: 0.6359 - val_accuracy: 0.6485\n",
      "Epoch 4/20\n",
      "6000/6000 [==============================] - 1s 94us/step - loss: 0.6393 - accuracy: 0.6428 - val_loss: 0.6386 - val_accuracy: 0.6336\n",
      "Epoch 5/20\n",
      "6000/6000 [==============================] - 1s 94us/step - loss: 0.6344 - accuracy: 0.6460 - val_loss: 0.6531 - val_accuracy: 0.6330\n",
      "Epoch 6/20\n",
      "6000/6000 [==============================] - 1s 93us/step - loss: 0.6269 - accuracy: 0.6582 - val_loss: 0.6197 - val_accuracy: 0.6720\n",
      "Epoch 7/20\n",
      "6000/6000 [==============================] - 1s 94us/step - loss: 0.6201 - accuracy: 0.6580 - val_loss: 0.6078 - val_accuracy: 0.6764\n",
      "Epoch 8/20\n",
      "6000/6000 [==============================] - 1s 94us/step - loss: 0.6163 - accuracy: 0.6600 - val_loss: 0.6029 - val_accuracy: 0.6826\n",
      "Epoch 9/20\n",
      "6000/6000 [==============================] - 1s 94us/step - loss: 0.6120 - accuracy: 0.6647 - val_loss: 0.6174 - val_accuracy: 0.6708\n",
      "Epoch 10/20\n",
      "6000/6000 [==============================] - 1s 95us/step - loss: 0.6084 - accuracy: 0.6742 - val_loss: 0.5918 - val_accuracy: 0.6863\n",
      "Epoch 11/20\n",
      "6000/6000 [==============================] - 1s 95us/step - loss: 0.6073 - accuracy: 0.6722 - val_loss: 0.5973 - val_accuracy: 0.6869\n",
      "Epoch 12/20\n",
      "6000/6000 [==============================] - 1s 96us/step - loss: 0.6016 - accuracy: 0.6815 - val_loss: 0.5867 - val_accuracy: 0.6875\n",
      "Epoch 13/20\n",
      "6000/6000 [==============================] - 1s 95us/step - loss: 0.6045 - accuracy: 0.6760 - val_loss: 0.6211 - val_accuracy: 0.6696\n",
      "Epoch 14/20\n",
      "6000/6000 [==============================] - 1s 110us/step - loss: 0.6028 - accuracy: 0.6783 - val_loss: 0.5946 - val_accuracy: 0.6913\n",
      "Epoch 15/20\n",
      "6000/6000 [==============================] - 1s 99us/step - loss: 0.6007 - accuracy: 0.6808 - val_loss: 0.5895 - val_accuracy: 0.6931\n",
      "Epoch 16/20\n",
      "6000/6000 [==============================] - 1s 97us/step - loss: 0.5992 - accuracy: 0.6815 - val_loss: 0.5955 - val_accuracy: 0.6925\n",
      "Epoch 17/20\n",
      "6000/6000 [==============================] - 1s 95us/step - loss: 0.5976 - accuracy: 0.6797 - val_loss: 0.5916 - val_accuracy: 0.6937\n",
      "Epoch 18/20\n",
      "6000/6000 [==============================] - 1s 95us/step - loss: 0.5964 - accuracy: 0.6852 - val_loss: 0.5903 - val_accuracy: 0.6944\n",
      "Epoch 19/20\n",
      "6000/6000 [==============================] - 1s 94us/step - loss: 0.5953 - accuracy: 0.6857 - val_loss: 0.5923 - val_accuracy: 0.6950\n",
      "Epoch 20/20\n",
      "6000/6000 [==============================] - 1s 95us/step - loss: 0.5952 - accuracy: 0.6865 - val_loss: 0.5816 - val_accuracy: 0.6950\n"
     ]
    }
   ],
   "source": [
    "history_rnn_pretrain = model.fit(train_seq_mat,\n",
    "                    train_df.target,\n",
    "                   epochs=20,\n",
    "                   batch_size = 128,\n",
    "                   validation_data =(val_seq_mat,val_df.target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_25 (Embedding)     (None, 25, 32)            384000    \n",
      "_________________________________________________________________\n",
      "lstm_14 (LSTM)               (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 392,353\n",
      "Trainable params: 392,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Embedding(input_dim=max_words, output_dim=embedding_dim,\n",
    "                           input_length = max_len))\n",
    "\n",
    "\n",
    "model.add(layers.LSTM(32))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "             loss = 'binary_crossentropy',\n",
    "             metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\school\\aconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6000 samples, validate on 1613 samples\n",
      "Epoch 1/20\n",
      "6000/6000 [==============================] - 1s 203us/step - loss: 0.6379 - accuracy: 0.6275 - val_loss: 0.5973 - val_accuracy: 0.7154\n",
      "Epoch 2/20\n",
      "6000/6000 [==============================] - 1s 153us/step - loss: 0.4624 - accuracy: 0.8150 - val_loss: 0.5090 - val_accuracy: 0.7756\n",
      "Epoch 3/20\n",
      "6000/6000 [==============================] - 1s 147us/step - loss: 0.3595 - accuracy: 0.8572 - val_loss: 0.4978 - val_accuracy: 0.7874\n",
      "Epoch 4/20\n",
      "6000/6000 [==============================] - 1s 151us/step - loss: 0.2942 - accuracy: 0.8828 - val_loss: 0.4847 - val_accuracy: 0.7830\n",
      "Epoch 5/20\n",
      "6000/6000 [==============================] - 1s 147us/step - loss: 0.2461 - accuracy: 0.9047 - val_loss: 0.5212 - val_accuracy: 0.7737\n",
      "Epoch 6/20\n",
      "6000/6000 [==============================] - 1s 147us/step - loss: 0.2177 - accuracy: 0.9172 - val_loss: 0.5527 - val_accuracy: 0.7644\n",
      "Epoch 7/20\n",
      "6000/6000 [==============================] - 1s 149us/step - loss: 0.1860 - accuracy: 0.9333 - val_loss: 0.6403 - val_accuracy: 0.7303\n",
      "Epoch 8/20\n",
      "6000/6000 [==============================] - 1s 149us/step - loss: 0.1681 - accuracy: 0.9400 - val_loss: 0.6277 - val_accuracy: 0.7471\n",
      "Epoch 9/20\n",
      "6000/6000 [==============================] - 1s 148us/step - loss: 0.1505 - accuracy: 0.9448 - val_loss: 0.7507 - val_accuracy: 0.7235\n",
      "Epoch 10/20\n",
      "6000/6000 [==============================] - 1s 145us/step - loss: 0.1356 - accuracy: 0.9497 - val_loss: 0.8018 - val_accuracy: 0.7285\n",
      "Epoch 11/20\n",
      "6000/6000 [==============================] - 1s 152us/step - loss: 0.1260 - accuracy: 0.9538 - val_loss: 0.9453 - val_accuracy: 0.6838\n",
      "Epoch 12/20\n",
      "6000/6000 [==============================] - 1s 148us/step - loss: 0.1161 - accuracy: 0.9568 - val_loss: 0.8717 - val_accuracy: 0.7173\n",
      "Epoch 13/20\n",
      "6000/6000 [==============================] - 1s 148us/step - loss: 0.1063 - accuracy: 0.9625 - val_loss: 0.9283 - val_accuracy: 0.7334\n",
      "Epoch 14/20\n",
      "6000/6000 [==============================] - 1s 148us/step - loss: 0.0984 - accuracy: 0.9635 - val_loss: 0.9623 - val_accuracy: 0.7210\n",
      "Epoch 15/20\n",
      "6000/6000 [==============================] - 1s 153us/step - loss: 0.0931 - accuracy: 0.9657 - val_loss: 1.0240 - val_accuracy: 0.7130\n",
      "Epoch 16/20\n",
      "6000/6000 [==============================] - 1s 178us/step - loss: 0.0869 - accuracy: 0.9685 - val_loss: 0.9351 - val_accuracy: 0.7161\n",
      "Epoch 17/20\n",
      "6000/6000 [==============================] - 1s 225us/step - loss: 0.0822 - accuracy: 0.9685 - val_loss: 1.0710 - val_accuracy: 0.7117\n",
      "Epoch 18/20\n",
      "6000/6000 [==============================] - 1s 173us/step - loss: 0.0789 - accuracy: 0.9705 - val_loss: 1.0951 - val_accuracy: 0.7037\n",
      "Epoch 19/20\n",
      "6000/6000 [==============================] - 1s 150us/step - loss: 0.0738 - accuracy: 0.9707 - val_loss: 1.1343 - val_accuracy: 0.7006\n",
      "Epoch 20/20\n",
      "6000/6000 [==============================] - 1s 157us/step - loss: 0.0721 - accuracy: 0.9727 - val_loss: 1.1948 - val_accuracy: 0.6944\n"
     ]
    }
   ],
   "source": [
    "history_lstm = model.fit(train_seq_mat,\n",
    "                    train_df.target,\n",
    "                   epochs=20,\n",
    "                   batch_size = 128,\n",
    "                   validation_data =(val_seq_mat,val_df.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_16 (Embedding)     (None, 25, 32)            384000    \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 25, 16)            3136      \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 16)                2112      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 389,537\n",
      "Trainable params: 5,537\n",
      "Non-trainable params: 384,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Embedding(input_dim=max_words, output_dim=embedding_dim,\n",
    "                           input_length = max_len,\n",
    "                          weights = [weight],\n",
    "                          trainable=False))\n",
    "\n",
    "\n",
    "model.add(layers.LSTM(32))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "             loss = 'binary_crossentropy',\n",
    "             metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6000 samples, validate on 1613 samples\n",
      "Epoch 1/20\n",
      "6000/6000 [==============================] - 2s 372us/step - loss: 0.6833 - accuracy: 0.5728 - val_loss: 0.6912 - val_accuracy: 0.5325\n",
      "Epoch 2/20\n",
      "6000/6000 [==============================] - 2s 269us/step - loss: 0.6682 - accuracy: 0.5885 - val_loss: 0.6555 - val_accuracy: 0.6262\n",
      "Epoch 3/20\n",
      "6000/6000 [==============================] - 2s 264us/step - loss: 0.6498 - accuracy: 0.6253 - val_loss: 0.6333 - val_accuracy: 0.6510\n",
      "Epoch 4/20\n",
      "6000/6000 [==============================] - 2s 265us/step - loss: 0.6360 - accuracy: 0.6465 - val_loss: 0.6208 - val_accuracy: 0.6813\n",
      "Epoch 5/20\n",
      "6000/6000 [==============================] - 2s 264us/step - loss: 0.6287 - accuracy: 0.6567 - val_loss: 0.6112 - val_accuracy: 0.6720\n",
      "Epoch 6/20\n",
      "6000/6000 [==============================] - 2s 269us/step - loss: 0.6278 - accuracy: 0.6588 - val_loss: 0.6158 - val_accuracy: 0.6900\n",
      "Epoch 7/20\n",
      "6000/6000 [==============================] - 2s 267us/step - loss: 0.6254 - accuracy: 0.6632 - val_loss: 0.5960 - val_accuracy: 0.6894\n",
      "Epoch 8/20\n",
      "6000/6000 [==============================] - 2s 263us/step - loss: 0.6216 - accuracy: 0.6592 - val_loss: 0.5996 - val_accuracy: 0.6950\n",
      "Epoch 9/20\n",
      "6000/6000 [==============================] - 2s 271us/step - loss: 0.6217 - accuracy: 0.6645 - val_loss: 0.5916 - val_accuracy: 0.6801\n",
      "Epoch 10/20\n",
      "6000/6000 [==============================] - 2s 273us/step - loss: 0.6168 - accuracy: 0.6678 - val_loss: 0.5904 - val_accuracy: 0.7043\n",
      "Epoch 11/20\n",
      "6000/6000 [==============================] - 2s 271us/step - loss: 0.6144 - accuracy: 0.6667 - val_loss: 0.5835 - val_accuracy: 0.6882\n",
      "Epoch 12/20\n",
      "6000/6000 [==============================] - 2s 274us/step - loss: 0.6135 - accuracy: 0.6677 - val_loss: 0.5867 - val_accuracy: 0.7074\n",
      "Epoch 13/20\n",
      "6000/6000 [==============================] - 2s 279us/step - loss: 0.6132 - accuracy: 0.6692 - val_loss: 0.5800 - val_accuracy: 0.6925\n",
      "Epoch 14/20\n",
      "6000/6000 [==============================] - 2s 288us/step - loss: 0.6092 - accuracy: 0.6727 - val_loss: 0.5846 - val_accuracy: 0.7099\n",
      "Epoch 15/20\n",
      "6000/6000 [==============================] - 2s 281us/step - loss: 0.6094 - accuracy: 0.6743 - val_loss: 0.5910 - val_accuracy: 0.7024\n",
      "Epoch 16/20\n",
      "6000/6000 [==============================] - 2s 269us/step - loss: 0.6075 - accuracy: 0.6793 - val_loss: 0.5798 - val_accuracy: 0.6801\n",
      "Epoch 17/20\n",
      "6000/6000 [==============================] - 2s 270us/step - loss: 0.6080 - accuracy: 0.6763 - val_loss: 0.5745 - val_accuracy: 0.7080\n",
      "Epoch 18/20\n",
      "6000/6000 [==============================] - 2s 270us/step - loss: 0.6083 - accuracy: 0.6747 - val_loss: 0.5748 - val_accuracy: 0.6882\n",
      "Epoch 19/20\n",
      "6000/6000 [==============================] - 2s 267us/step - loss: 0.6068 - accuracy: 0.6798 - val_loss: 0.5707 - val_accuracy: 0.7080\n",
      "Epoch 20/20\n",
      "6000/6000 [==============================] - 2s 271us/step - loss: 0.6048 - accuracy: 0.6777 - val_loss: 0.5708 - val_accuracy: 0.7074\n"
     ]
    }
   ],
   "source": [
    "history_lstm_pretrain = model.fit(train_seq_mat,\n",
    "                    train_df.target,\n",
    "                   epochs=20,\n",
    "                   batch_size = 128,\n",
    "                   validation_data =(val_seq_mat,val_df.target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_22 (Embedding)     (None, 25, 32)            384000    \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 23, 32)            3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 7, 32)             0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 224)               0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 32)                7200      \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 394,337\n",
      "Trainable params: 394,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Embedding(input_dim=max_words, output_dim=embedding_dim,\n",
    "                           input_length = max_len))\n",
    "\n",
    "model.add(layers.Conv1D(32, 3, activation='relu'))\n",
    "model.add(layers.MaxPooling1D(3))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "             loss = 'binary_crossentropy',\n",
    "             metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\school\\aconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6000 samples, validate on 1613 samples\n",
      "Epoch 1/20\n",
      "6000/6000 [==============================] - 0s 66us/step - loss: 0.6656 - accuracy: 0.6020 - val_loss: 0.6800 - val_accuracy: 0.5518\n",
      "Epoch 2/20\n",
      "6000/6000 [==============================] - 0s 40us/step - loss: 0.5296 - accuracy: 0.7778 - val_loss: 0.5380 - val_accuracy: 0.7508\n",
      "Epoch 3/20\n",
      "6000/6000 [==============================] - 0s 41us/step - loss: 0.3653 - accuracy: 0.8603 - val_loss: 0.5177 - val_accuracy: 0.7539\n",
      "Epoch 4/20\n",
      "6000/6000 [==============================] - 0s 40us/step - loss: 0.2836 - accuracy: 0.8910 - val_loss: 0.5316 - val_accuracy: 0.7508\n",
      "Epoch 5/20\n",
      "6000/6000 [==============================] - 0s 40us/step - loss: 0.2301 - accuracy: 0.9142 - val_loss: 0.5732 - val_accuracy: 0.7421\n",
      "Epoch 6/20\n",
      "6000/6000 [==============================] - 0s 42us/step - loss: 0.1900 - accuracy: 0.9288 - val_loss: 0.6340 - val_accuracy: 0.7316\n",
      "Epoch 7/20\n",
      "6000/6000 [==============================] - 0s 39us/step - loss: 0.1590 - accuracy: 0.9388 - val_loss: 0.6789 - val_accuracy: 0.7322\n",
      "Epoch 8/20\n",
      "6000/6000 [==============================] - 0s 39us/step - loss: 0.1381 - accuracy: 0.9480 - val_loss: 0.7457 - val_accuracy: 0.7272\n",
      "Epoch 9/20\n",
      "6000/6000 [==============================] - 0s 41us/step - loss: 0.1197 - accuracy: 0.9552 - val_loss: 0.8176 - val_accuracy: 0.7291\n",
      "Epoch 10/20\n",
      "6000/6000 [==============================] - 0s 42us/step - loss: 0.1084 - accuracy: 0.9597 - val_loss: 0.8741 - val_accuracy: 0.7185\n",
      "Epoch 11/20\n",
      "6000/6000 [==============================] - 0s 39us/step - loss: 0.0971 - accuracy: 0.9633 - val_loss: 0.9462 - val_accuracy: 0.7105\n",
      "Epoch 12/20\n",
      "6000/6000 [==============================] - 0s 40us/step - loss: 0.0890 - accuracy: 0.9648 - val_loss: 0.9980 - val_accuracy: 0.7049\n",
      "Epoch 13/20\n",
      "6000/6000 [==============================] - 0s 41us/step - loss: 0.0848 - accuracy: 0.9662 - val_loss: 1.0256 - val_accuracy: 0.7099\n",
      "Epoch 14/20\n",
      "6000/6000 [==============================] - 0s 41us/step - loss: 0.0794 - accuracy: 0.9675 - val_loss: 1.0656 - val_accuracy: 0.7030\n",
      "Epoch 15/20\n",
      "6000/6000 [==============================] - 0s 39us/step - loss: 0.0764 - accuracy: 0.9678 - val_loss: 1.1057 - val_accuracy: 0.6968\n",
      "Epoch 16/20\n",
      "6000/6000 [==============================] - 0s 40us/step - loss: 0.0730 - accuracy: 0.9712 - val_loss: 1.1315 - val_accuracy: 0.6987\n",
      "Epoch 17/20\n",
      "6000/6000 [==============================] - 0s 42us/step - loss: 0.0700 - accuracy: 0.9725 - val_loss: 1.1401 - val_accuracy: 0.6968\n",
      "Epoch 18/20\n",
      "6000/6000 [==============================] - 0s 42us/step - loss: 0.0673 - accuracy: 0.9708 - val_loss: 1.1569 - val_accuracy: 0.6975\n",
      "Epoch 19/20\n",
      "6000/6000 [==============================] - 0s 40us/step - loss: 0.0660 - accuracy: 0.9717 - val_loss: 1.2074 - val_accuracy: 0.6906\n",
      "Epoch 20/20\n",
      "6000/6000 [==============================] - 0s 39us/step - loss: 0.0645 - accuracy: 0.9723 - val_loss: 1.1888 - val_accuracy: 0.6919\n"
     ]
    }
   ],
   "source": [
    "history_cnn = model.fit(train_seq_mat,\n",
    "                    train_df.target,\n",
    "                   epochs=20,\n",
    "                   batch_size = 128,\n",
    "                   validation_data =(val_seq_mat,val_df.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_12 (Embedding)     (None, 25, 32)            384000    \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 23, 32)            3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 7, 32)             0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 224)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 32)                7200      \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 394,337\n",
      "Trainable params: 10,337\n",
      "Non-trainable params: 384,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Embedding(input_dim=max_words, output_dim=embedding_dim,\n",
    "                           input_length = max_len,\n",
    "                          weights = [weight],\n",
    "                          trainable=False))\n",
    "\n",
    "model.add(layers.Conv1D(32, 3, activation='relu'))\n",
    "model.add(layers.MaxPooling1D(3))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "             loss = 'binary_crossentropy',\n",
    "             metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6000 samples, validate on 1613 samples\n",
      "Epoch 1/20\n",
      "6000/6000 [==============================] - 0s 57us/step - loss: 0.6712 - accuracy: 0.5893 - val_loss: 0.6799 - val_accuracy: 0.5511\n",
      "Epoch 2/20\n",
      "6000/6000 [==============================] - 0s 32us/step - loss: 0.6546 - accuracy: 0.6142 - val_loss: 0.6586 - val_accuracy: 0.5964\n",
      "Epoch 3/20\n",
      "6000/6000 [==============================] - 0s 36us/step - loss: 0.6443 - accuracy: 0.6292 - val_loss: 0.6580 - val_accuracy: 0.5989\n",
      "Epoch 4/20\n",
      "6000/6000 [==============================] - 0s 34us/step - loss: 0.6370 - accuracy: 0.6452 - val_loss: 0.6379 - val_accuracy: 0.6510\n",
      "Epoch 5/20\n",
      "6000/6000 [==============================] - 0s 33us/step - loss: 0.6316 - accuracy: 0.6523 - val_loss: 0.6268 - val_accuracy: 0.6764\n",
      "Epoch 6/20\n",
      "6000/6000 [==============================] - 0s 34us/step - loss: 0.6273 - accuracy: 0.6610 - val_loss: 0.6219 - val_accuracy: 0.6789\n",
      "Epoch 7/20\n",
      "6000/6000 [==============================] - 0s 32us/step - loss: 0.6225 - accuracy: 0.6605 - val_loss: 0.6160 - val_accuracy: 0.6745\n",
      "Epoch 8/20\n",
      "6000/6000 [==============================] - 0s 31us/step - loss: 0.6172 - accuracy: 0.6668 - val_loss: 0.6147 - val_accuracy: 0.6869\n",
      "Epoch 9/20\n",
      "6000/6000 [==============================] - 0s 31us/step - loss: 0.6148 - accuracy: 0.6670 - val_loss: 0.6042 - val_accuracy: 0.6857\n",
      "Epoch 10/20\n",
      "6000/6000 [==============================] - 0s 34us/step - loss: 0.6128 - accuracy: 0.6687 - val_loss: 0.6029 - val_accuracy: 0.6906\n",
      "Epoch 11/20\n",
      "6000/6000 [==============================] - 0s 32us/step - loss: 0.6098 - accuracy: 0.6778 - val_loss: 0.6075 - val_accuracy: 0.6993\n",
      "Epoch 12/20\n",
      "6000/6000 [==============================] - 0s 33us/step - loss: 0.6072 - accuracy: 0.6757 - val_loss: 0.6079 - val_accuracy: 0.6931\n",
      "Epoch 13/20\n",
      "6000/6000 [==============================] - 0s 33us/step - loss: 0.6054 - accuracy: 0.6765 - val_loss: 0.6151 - val_accuracy: 0.6857\n",
      "Epoch 14/20\n",
      "6000/6000 [==============================] - 0s 33us/step - loss: 0.6037 - accuracy: 0.6777 - val_loss: 0.5943 - val_accuracy: 0.6900\n",
      "Epoch 15/20\n",
      "6000/6000 [==============================] - 0s 32us/step - loss: 0.5999 - accuracy: 0.6847 - val_loss: 0.6080 - val_accuracy: 0.6888\n",
      "Epoch 16/20\n",
      "6000/6000 [==============================] - 0s 35us/step - loss: 0.5983 - accuracy: 0.6900 - val_loss: 0.6382 - val_accuracy: 0.6466\n",
      "Epoch 17/20\n",
      "6000/6000 [==============================] - 0s 33us/step - loss: 0.5978 - accuracy: 0.6877 - val_loss: 0.5877 - val_accuracy: 0.7024\n",
      "Epoch 18/20\n",
      "6000/6000 [==============================] - 0s 32us/step - loss: 0.5924 - accuracy: 0.6877 - val_loss: 0.6147 - val_accuracy: 0.6758\n",
      "Epoch 19/20\n",
      "6000/6000 [==============================] - 0s 36us/step - loss: 0.5911 - accuracy: 0.6942 - val_loss: 0.5880 - val_accuracy: 0.7105\n",
      "Epoch 20/20\n",
      "6000/6000 [==============================] - 0s 33us/step - loss: 0.5923 - accuracy: 0.6908 - val_loss: 0.6155 - val_accuracy: 0.6770\n"
     ]
    }
   ],
   "source": [
    "history_cnn_pretrain = model.fit(train_seq_mat,\n",
    "                    train_df.target,\n",
    "                   epochs=20,\n",
    "                   batch_size = 128,\n",
    "                   validation_data =(val_seq_mat,val_df.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('history_dense.npy', history_dense.history)\n",
    "\n",
    "np.save('history_rnn.npy', history_rnn.history)\n",
    "np.save('history_rnn_pretrain.npy', history_rnn_pretrain.history)\n",
    "\n",
    "\n",
    "np.save('history_lstm.npy', history_lstm.history)\n",
    "np.save('history_lstm_pretrain.npy', history_lstm_pretrain.history)\n",
    "\n",
    "np.save('history_cnn.npy', history_cnn.history)\n",
    "np.save('history_cnn_pretrain.npy', history_cnn_pretrain.history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
